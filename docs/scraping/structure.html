
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Structure &#8212; CAN Scrapers  documentation</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Writing Scrapers" href="writing_scrapers.html" />
    <link rel="prev" title="Developer Installation" href="installation.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="structure">
<span id="scraper-structure"></span><h1>Structure<a class="headerlink" href="#structure" title="Permalink to this headline">¶</a></h1>
<p>Each scraper in <code class="docutils literal notranslate"><span class="pre">can-scrapers</span></code> is a Python class within the <code class="docutils literal notranslate"><span class="pre">can_tools/scrapers</span></code> Python package</p>
<div class="section" id="organization">
<h2>Organization<a class="headerlink" href="#organization" title="Permalink to this headline">¶</a></h2>
<p>The scrapers are organized in a few sub-directories of <code class="docutils literal notranslate"><span class="pre">can_tools/scrapers</span></code>:</p>
<ul class="simple">
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">official/</span></code>: these contain data from official federal, state, or county government websites (including health departments, CDC, HHS, etc.).</dt><dd><ul>
<li><p>Scrapers targeting a state level dashboard are put in <code class="docutils literal notranslate"><span class="pre">official/XX</span></code> where <code class="docutils literal notranslate"><span class="pre">XX</span></code> is the two letter state abbreviation (for example <code class="docutils literal notranslate"><span class="pre">official/NM/nm_vaccine.py</span></code> for a scraper collecting vaccine data for counties in the state of New Mexico)</p></li>
<li><p>Scrapers for a specific county are organized into <code class="docutils literal notranslate"><span class="pre">official/XX/counties</span></code> directory. For example <code class="docutils literal notranslate"><span class="pre">official/XX/counties/la_county_vaccine.py</span></code> might have a scraper that scrapes vaccine data from the Los Angeles county dashboard</p></li>
</ul>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">usafacts/</span></code>: scrapers for the county-level data provided by usafacts</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">uscensus/</span></code>: scrapers that obtain demographic data from the US Census</p></li>
</ul>
</div>
<div class="section" id="class-hierarchy">
<h2>Class Hierarchy<a class="headerlink" href="#class-hierarchy" title="Permalink to this headline">¶</a></h2>
<p>Let’s consider an example scraper and its lineage: the <code class="docutils literal notranslate"><span class="pre">NewJerseyVaccineCounty</span></code> class found in <code class="docutils literal notranslate"><span class="pre">can_tools/scrapers/official/NJ/nj_vaccine.py</span></code></p>
<p>Let <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">&lt;:</span> <span class="pre">B</span></code> represent the phrase “A is a subclass of B”</p>
<p>Then the following is true about <code class="docutils literal notranslate"><span class="pre">NewJerseyVaccineCounty</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">NewJerseyVaccineCounty</span> <span class="o">&lt;</span><span class="p">:</span> <span class="n">ArcGIS</span> <span class="o">&lt;</span><span class="p">:</span> <span class="n">StateDashboard</span> <span class="o">&lt;</span><span class="p">:</span> <span class="n">DatasetBase</span>
</pre></div>
</div>
<p>Each of the parent classes has a specific purpose and adds in functionality</p>
<p>We’ll start at the top of the hierarchy and work our way down</p>
<div class="section" id="datasetbase">
<h3>DatasetBase<a class="headerlink" href="#datasetbase" title="Permalink to this headline">¶</a></h3>
<p>Each scraper must be a subclass of the core <code class="docutils literal notranslate"><span class="pre">DatasetBase</span></code> class.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">DatasetBase</span></code> class is defined in <code class="docutils literal notranslate"><span class="pre">can_tools/scrapers/base.py</span></code> and does a number of things:</p>
<ul class="simple">
<li><p>Automatically generates a prefect flow for execution of the scraper in the production pipeline</p></li>
<li><p>Abstracts away all non-scraper specific IO. This includes writing out temporary results, storing in cloud buckets, inserting into database, etc.</p></li>
<li><p>Doing some common data quality checks (called <cite>validation</cite>)</p></li>
<li><p>Defines helper methods for wranging data, these include methods <code class="docutils literal notranslate"><span class="pre">extract_CMU</span></code></p></li>
<li><dl class="simple">
<dt>Defines a common interface that must be satisfied by all scrapers. These are abstract methods must be implemented by a subclass and include:</dt><dd><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">fetch</span></code>: responsible for doing network operations to collect data</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">normalize</span></code>: consumes the output of <code class="docutils literal notranslate"><span class="pre">fetch</span></code> and returns normalized data (see below)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">put</span></code>: consumes output of <code class="docutils literal notranslate"><span class="pre">normalize</span></code> and stores into database</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>Most of our scrapers are from official government or health department websites. There are common tasks and configuration for all scrapers of this type</p>
<p>For this reason, there are other abstract classes that inherit from <code class="docutils literal notranslate"><span class="pre">DatasetBase</span></code></p>
<p>These include: <code class="docutils literal notranslate"><span class="pre">StateDashbord</span></code>, <code class="docutils literal notranslate"><span class="pre">CountyDashboard</span></code>, <code class="docutils literal notranslate"><span class="pre">FederalDashboard</span></code></p>
<p>We’ll talk about these next</p>
</div>
<div class="section" id="statedashboard">
<span id="state-dashboard"></span><h3>StateDashboard<a class="headerlink" href="#statedashboard" title="Permalink to this headline">¶</a></h3>
<p>The majority of our scrapers collect data from a state maintained dashboard</p>
<p>The <code class="docutils literal notranslate"><span class="pre">StateDashboard</span></code> class (defined in <code class="docutils literal notranslate"><span class="pre">can_tools/scrapers/official/base.py</span></code>) adds some tools to make getting data from these sources easier:</p>
<ul class="simple">
<li><p>Defines <code class="docutils literal notranslate"><span class="pre">table</span></code>, <code class="docutils literal notranslate"><span class="pre">provider</span></code>, and <code class="docutils literal notranslate"><span class="pre">data_type</span></code> class attributes</p></li>
<li><p>Methods <code class="docutils literal notranslate"><span class="pre">put</span></code> and <code class="docutils literal notranslate"><span class="pre">_put_exec</span></code>: the code needed to push data to the database. Note, this means that none of our scraper classes (at the bottom of the hierarchy like <code class="docutils literal notranslate"><span class="pre">NewJerseyVaccineCounty</span></code>) need to worry about database interactions</p></li>
<li><p>Methods <code class="docutils literal notranslate"><span class="pre">_rename_or_add_date_and_location</span></code> and <code class="docutils literal notranslate"><span class="pre">_reshape_variables</span></code>: tools for cleaning data (see below)</p></li>
</ul>
<dl class="py function">
<dt id="can_tools.scrapers.official.base.StateDashboard._rename_or_add_date_and_location">
<code class="sig-prename descclassname"><span class="pre">can_tools.scrapers.official.base.StateDashboard.</span></code><code class="sig-name descname"><span class="pre">_rename_or_add_date_and_location</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">pandas.core.frame.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">location_name_column</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">location_column</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">location_names_to_drop</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">locations_to_drop</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">date_column</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">date</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">pandas._libs.tslibs.timestamps.Timestamp</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timezone</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">apply_title_case</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#can_tools.scrapers.official.base.StateDashboard._rename_or_add_date_and_location" title="Permalink to this definition">¶</a></dt>
<dd><p>Renames or adds date and location columns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – Input data</p></li>
<li><p><strong>location_name_column</strong> – Name of column with location name</p></li>
<li><p><strong>location_column</strong> – Name of column with location (fips)</p></li>
<li><p><strong>location_names_to_drop</strong> – List of values in <cite>location_name_column</cite> that should be dropped</p></li>
<li><p><strong>locations_to_drop</strong> – List of values in <cite>location_column</cite> that should be dropped</p></li>
<li><p><strong>date_column</strong> – Name of Column containing date.</p></li>
<li><p><strong>date</strong> – Date for data</p></li>
<li><p><strong>timezone</strong> – Timezone of data if date or date_column not supplied.</p></li>
<li><p><strong>apply_title_case</strong> – If True will make location name title case.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Data with date and location columns normalized.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>data</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="can_tools.scrapers.official.base.StateDashboard._reshape_variables">
<code class="sig-prename descclassname"><span class="pre">can_tools.scrapers.official.base.StateDashboard.</span></code><code class="sig-name descname"><span class="pre">_reshape_variables</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">pandas.core.frame.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variable_map</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="writing_scrapers.html#can_tools.scrapers.base.CMU" title="can_tools.scrapers.base.CMU"><span class="pre">can_tools.scrapers.base.CMU</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">pandas.core.frame.DataFrame</span><a class="headerlink" href="#can_tools.scrapers.official.base.StateDashboard._reshape_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Reshape columns in data to be long form definitions defined in <cite>variable_map</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – Input data</p></li>
<li><p><strong>variable_map</strong> (<em>Union</em><em>[</em><em>str</em><em>,</em><em>int</em><em>]</em>) – Map from column name to output variables</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Reshaped DataFrame.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>data</p>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">CountyDashboard</span></code> and <code class="docutils literal notranslate"><span class="pre">FederalDashboard</span></code> inherit from <code class="docutils literal notranslate"><span class="pre">StateDashboard</span></code> and update the <code class="docutils literal notranslate"><span class="pre">provider</span></code> attribute. These are also defined in <code class="docutils literal notranslate"><span class="pre">can_tools/scrapers/official/base.py</span></code></p>
</div>
</div>
<div class="section" id="dashboard-type-subclasses">
<span id="dashboard-parent-classes"></span><h3>Dashboard Type subclasses<a class="headerlink" href="#dashboard-type-subclasses" title="Permalink to this headline">¶</a></h3>
<p>The next level in the hierarchy is a subclass for a specific type of dashboard technology</p>
<p>In the <code class="docutils literal notranslate"><span class="pre">NewJerseyVaccineCounty</span></code> example, this was the <code class="docutils literal notranslate"><span class="pre">ArcGIS</span></code> class</p>
<p>This subclass inherits from <code class="docutils literal notranslate"><span class="pre">StateDashboard</span></code> (so a scraper for an ArcGIS dashbaord only need to subclass <code class="docutils literal notranslate"><span class="pre">ArcGIS</span></code> and will get all goodies from <code class="docutils literal notranslate"><span class="pre">StateDashboard</span></code> and <code class="docutils literal notranslate"><span class="pre">DatasetBase</span></code>) and adds in tools specific for interacting with ArcGIS dashboards</p>
<p><code class="docutils literal notranslate"><span class="pre">ArcGIS</span></code> has some siblings:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">SODA</span></code>: interacting with resources that adhere to the SODA standard</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TableauDashboard</span></code>: tools for extracting data from Tableau based dashboards</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MicrosoftBIDashboard</span></code>: tools for extracting data from Microsoft BI dashboards</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GoogleDataStudioDashboard</span></code>: tools for extracting data from Google Data Studio dashboards</p></li>
</ul>
<p>In general, when you begin a new scraper, the initial steps are</p>
<ol class="arabic simple">
<li><p>Determine the technology used to create the dashboard</p></li>
<li><p>See if we have a subclass specific to that dashboard type</p></li>
<li><p>See examples of existing scrapers that build on that subclass to get a jump start on how to structure your new scraper</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The technology-specific parent classes are defined in <code class="docutils literal notranslate"><span class="pre">can_tools/scrapers/official/base.py</span></code></p>
</div>
</div>
</div>
<div class="section" id="scraper-lifecycle">
<span id="id1"></span><h2>Scraper Lifecycle<a class="headerlink" href="#scraper-lifecycle" title="Permalink to this headline">¶</a></h2>
<p>With all that in mind, we now lay out the lifecycle of a scraper when it runs in production</p>
<p>We will do this by writing code needed for running the scraper</p>
<div class="highlight-python notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="n">scraper</span> <span class="o">=</span> <span class="n">NewJerseyVaccineCounty</span><span class="p">()</span>
<span class="n">raw</span> <span class="o">=</span> <span class="n">scraper</span><span class="o">.</span><span class="n">fetch</span><span class="p">()</span>
<span class="n">clean</span> <span class="o">=</span> <span class="n">scraper</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">raw</span><span class="p">)</span>
<span class="n">scraper</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="n">clean</span><span class="p">)</span>
<span class="n">scraper</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">clean</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<p>The line by line description of this code is</p>
<ol class="arabic simple">
<li><p>Create an instance of the scraper class. We can optionally pass <code class="docutils literal notranslate"><span class="pre">execution_dt</span></code> as an argument</p></li>
<li><p>Call the <code class="docutils literal notranslate"><span class="pre">.fetch</span></code> method to do network requests and get <code class="docutils literal notranslate"><span class="pre">raw</span></code> data. This method is typically defined directly in the child class</p></li>
<li><p>Call the <code class="docutils literal notranslate"><span class="pre">.normalize(raw)</span></code> method to get a cleaned DataFrame. This method is also typically defined directly in the child class. Implementing the <code class="docutils literal notranslate"><span class="pre">.fetch</span></code> and <code class="docutils literal notranslate"><span class="pre">.normalize</span></code> methods is the core of what we mean when we say “write a scraper”</p></li>
<li><p>Call the <code class="docutils literal notranslate"><span class="pre">.validate(clean)</span></code> method to check the data. There is a default <code class="docutils literal notranslate"><span class="pre">validate</span></code> method in <code class="docutils literal notranslate"><span class="pre">DatasetBase</span></code>, but you can override if you know something specific needs to be checked for the scraper you are working on</p></li>
<li><p>Call <code class="docutils literal notranslate"><span class="pre">.put(engine,</span> <span class="pre">clean)</span></code> to store the data in the database backing the sqlalchemy Engine <code class="docutils literal notranslate"><span class="pre">engine</span></code>. This is written in <code class="docutils literal notranslate"><span class="pre">StateDashboard</span></code> and should not need to be overwridden in child classes</p></li>
</ol>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">CAN Scrapers</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Data Scraping</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="installation.html">Developer Installation</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="writing_scrapers.html">Writing Scrapers</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../infrastructure/index.html">CAN Scraper Infrastructure</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index.html">Data Scraping</a><ul>
      <li>Previous: <a href="installation.html" title="previous chapter">Developer Installation</a></li>
      <li>Next: <a href="writing_scrapers.html" title="next chapter">Writing Scrapers</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020-2021, CAN Developers.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.5.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/scraping/structure.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>